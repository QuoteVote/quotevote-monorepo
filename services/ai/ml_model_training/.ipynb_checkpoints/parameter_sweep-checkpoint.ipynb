{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ml_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yr-jdNv8lBQv"
   },
   "source": [
    "# Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RzEiFj595ETL"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.stats import norm\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "import torch.utils.data as data\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KjrT9iHp633a",
    "outputId": "0bdaa023-5617-43b7-8374-7bff6672ed4b"
   },
   "outputs": [],
   "source": [
    "# Use GOOGLE_APPLICATION_CREDENTIALS env variable to reference the service account key\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"Scoreboard-ML-be7ebac08a24.json\"\n",
    "\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A4WEaXNvk-AK"
   },
   "source": [
    "# Create the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip if dataset has been created in storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLoWgjHk_cXC"
   },
   "outputs": [],
   "source": [
    "# Connect to BigQuery to run the query\n",
    "bq_client=bigquery.Client()\n",
    "\n",
    "# Download query results.\n",
    "query_string = \"\"\"\n",
    "SELECT *\n",
    "FROM `fh-bigquery.reddit_comments.2016_12`\n",
    "WHERE body not in ('[deleted]','[removed]')\n",
    "AND subreddit='cars'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LmFDljk-i2IT"
   },
   "outputs": [],
   "source": [
    "query_job=bq_client.query(query_string) # API Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old Buckets\n",
    "#custom_buckets = [-130,0,1,10,50,1500]\n",
    "#labels=['Downvoted','No Votes','2-10 Votes','11-50 Votes','50+ Votes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71GR4WGK_kV6"
   },
   "outputs": [],
   "source": [
    "# Call the to_dataframe method on the reader to write the entire stream to a pandas DataFrame\n",
    "rows_df=query_job.result().to_dataframe() # Waits for query to finish\n",
    "new_df=rows_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>score_hidden</th>\n",
       "      <th>archived</th>\n",
       "      <th>name</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>downs</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>score</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>gilded</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>ups</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey Matt, I didn't get a chance to read the ar...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>gropingpriest</td>\n",
       "      <td>'09 Cobalt SS t/c</td>\n",
       "      <td>None</td>\n",
       "      <td>1482193840</td>\n",
       "      <td>t5_2qhl2</td>\n",
       "      <td>t3_5j8dou</td>\n",
       "      <td>t3_5j8dou</td>\n",
       "      <td>-4</td>\n",
       "      <td>1483898510</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dbeiwkd</td>\n",
       "      <td>cars</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What, did it fall down behind the washing mach...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ArmourChinker</td>\n",
       "      <td>Commodore ����</td>\n",
       "      <td>None</td>\n",
       "      <td>1481770677</td>\n",
       "      <td>t5_2qhl2</td>\n",
       "      <td>t3_5ies4g</td>\n",
       "      <td>t3_5ies4g</td>\n",
       "      <td>-9</td>\n",
       "      <td>1483775228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>db7ofxv</td>\n",
       "      <td>cars</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Says the guy with the rwd subaru.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2az-fe</td>\n",
       "      <td>13 BMW 535xi, 13 Toyota Highlander, 04 Toyota ...</td>\n",
       "      <td>None</td>\n",
       "      <td>1482648961</td>\n",
       "      <td>t5_2qhl2</td>\n",
       "      <td>t3_5k52fn</td>\n",
       "      <td>t1_dblr1ml</td>\n",
       "      <td>25</td>\n",
       "      <td>1484029141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dblvijb</td>\n",
       "      <td>cars</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looks about right to me [red 570s](http://www....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>jebusv20</td>\n",
       "      <td>VW Polo GTi 1.4TSI</td>\n",
       "      <td>None</td>\n",
       "      <td>1481520805</td>\n",
       "      <td>t5_2qhl2</td>\n",
       "      <td>t3_5huw99</td>\n",
       "      <td>t3_5huw99</td>\n",
       "      <td>75</td>\n",
       "      <td>1483664660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>db372d8</td>\n",
       "      <td>cars</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What do you think the GT is going to be worth ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Spicy_Curry</td>\n",
       "      <td>2016 340xi ; 2017 GTI</td>\n",
       "      <td>None</td>\n",
       "      <td>1482389580</td>\n",
       "      <td>t5_2qhl2</td>\n",
       "      <td>t3_5jova0</td>\n",
       "      <td>t3_5jova0</td>\n",
       "      <td>66</td>\n",
       "      <td>1483958547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dbhwl61</td>\n",
       "      <td>cars</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body score_hidden archived  \\\n",
       "0  Hey Matt, I didn't get a chance to read the ar...         None     None   \n",
       "1  What, did it fall down behind the washing mach...         None     None   \n",
       "2                  Says the guy with the rwd subaru.         None     None   \n",
       "3  looks about right to me [red 570s](http://www....         None     None   \n",
       "4  What do you think the GT is going to be worth ...         None     None   \n",
       "\n",
       "   name         author                                  author_flair_text  \\\n",
       "0  None  gropingpriest                                  '09 Cobalt SS t/c   \n",
       "1  None  ArmourChinker                                     Commodore ����   \n",
       "2  None         2az-fe  13 BMW 535xi, 13 Toyota Highlander, 04 Toyota ...   \n",
       "3  None       jebusv20                                 VW Polo GTi 1.4TSI   \n",
       "4  None    Spicy_Curry                              2016 340xi ; 2017 GTI   \n",
       "\n",
       "  downs  created_utc subreddit_id    link_id   parent_id  score  retrieved_on  \\\n",
       "0  None   1482193840     t5_2qhl2  t3_5j8dou   t3_5j8dou     -4    1483898510   \n",
       "1  None   1481770677     t5_2qhl2  t3_5ies4g   t3_5ies4g     -9    1483775228   \n",
       "2  None   1482648961     t5_2qhl2  t3_5k52fn  t1_dblr1ml     25    1484029141   \n",
       "3  None   1481520805     t5_2qhl2  t3_5huw99   t3_5huw99     75    1483664660   \n",
       "4  None   1482389580     t5_2qhl2  t3_5jova0   t3_5jova0     66    1483958547   \n",
       "\n",
       "   controversiality  gilded       id subreddit   ups distinguished  \\\n",
       "0                 1       0  dbeiwkd      cars  None          None   \n",
       "1                 0       0  db7ofxv      cars  None          None   \n",
       "2                 0       0  dblvijb      cars  None          None   \n",
       "3                 0       0  db372d8      cars  None          None   \n",
       "4                 0       0  dbhwl61      cars  None          None   \n",
       "\n",
       "  author_flair_css_class  \n",
       "0                         \n",
       "1                         \n",
       "2                         \n",
       "3                         \n",
       "4                         "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108069/108069 [18:05<00:00, 99.58it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108069"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []\n",
    "for body in tqdm.tqdm(new_df.body.tolist()):\n",
    "    doc = nlp(body)\n",
    "    features.append('|'.join([tok.lemma_.lower() for tok in doc]))\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    108069.000000\n",
       "mean          6.298948\n",
       "std          23.469071\n",
       "min        -125.000000\n",
       "25%           1.000000\n",
       "50%           2.000000\n",
       "75%           5.000000\n",
       "max        1358.000000\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>score_hidden</th>\n",
       "      <th>archived</th>\n",
       "      <th>name</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>downs</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>...</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>gilded</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>ups</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>normalized_score</th>\n",
       "      <th>lemma_array</th>\n",
       "      <th>body_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey Matt, I didn't get a chance to read the ar...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>gropingpriest</td>\n",
       "      <td>'09 Cobalt SS t/c</td>\n",
       "      <td>None</td>\n",
       "      <td>1482193840</td>\n",
       "      <td>t5_2qhl2</td>\n",
       "      <td>t3_5j8dou</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dbeiwkd</td>\n",
       "      <td>cars</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>33.0</td>\n",
       "      <td>hey|Matt|,|-PRON-|do|not|get|a|chance|to|read|...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What, did it fall down behind the washing mach...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ArmourChinker</td>\n",
       "      <td>Commodore ����</td>\n",
       "      <td>None</td>\n",
       "      <td>1481770677</td>\n",
       "      <td>t5_2qhl2</td>\n",
       "      <td>t3_5ies4g</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>db7ofxv</td>\n",
       "      <td>cars</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>25.0</td>\n",
       "      <td>what|,|do|-PRON-|fall|down|behind|the|washing|...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Says the guy with the rwd subaru.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2az-fe</td>\n",
       "      <td>13 BMW 535xi, 13 Toyota Highlander, 04 Toyota ...</td>\n",
       "      <td>None</td>\n",
       "      <td>1482648961</td>\n",
       "      <td>t5_2qhl2</td>\n",
       "      <td>t3_5k52fn</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dblvijb</td>\n",
       "      <td>cars</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>78.0</td>\n",
       "      <td>say|the|guy|with|the|rwd|subaru|.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looks about right to me [red 570s](http://www....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>jebusv20</td>\n",
       "      <td>VW Polo GTi 1.4TSI</td>\n",
       "      <td>None</td>\n",
       "      <td>1481520805</td>\n",
       "      <td>t5_2qhl2</td>\n",
       "      <td>t3_5huw99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>db372d8</td>\n",
       "      <td>cars</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>100.0</td>\n",
       "      <td>look|about|right|to|-PRON-|[|red|570s](http://...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What do you think the GT is going to be worth ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Spicy_Curry</td>\n",
       "      <td>2016 340xi ; 2017 GTI</td>\n",
       "      <td>None</td>\n",
       "      <td>1482389580</td>\n",
       "      <td>t5_2qhl2</td>\n",
       "      <td>t3_5jova0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dbhwl61</td>\n",
       "      <td>cars</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>99.0</td>\n",
       "      <td>what|do|-PRON-|think|the|GT|be|go|to|be|worth|...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body score_hidden archived  \\\n",
       "0  Hey Matt, I didn't get a chance to read the ar...         None     None   \n",
       "1  What, did it fall down behind the washing mach...         None     None   \n",
       "2                  Says the guy with the rwd subaru.         None     None   \n",
       "3  looks about right to me [red 570s](http://www....         None     None   \n",
       "4  What do you think the GT is going to be worth ...         None     None   \n",
       "\n",
       "   name         author                                  author_flair_text  \\\n",
       "0  None  gropingpriest                                  '09 Cobalt SS t/c   \n",
       "1  None  ArmourChinker                                     Commodore ����   \n",
       "2  None         2az-fe  13 BMW 535xi, 13 Toyota Highlander, 04 Toyota ...   \n",
       "3  None       jebusv20                                 VW Polo GTi 1.4TSI   \n",
       "4  None    Spicy_Curry                              2016 340xi ; 2017 GTI   \n",
       "\n",
       "  downs  created_utc subreddit_id    link_id  ... controversiality  gilded  \\\n",
       "0  None   1482193840     t5_2qhl2  t3_5j8dou  ...                1       0   \n",
       "1  None   1481770677     t5_2qhl2  t3_5ies4g  ...                0       0   \n",
       "2  None   1482648961     t5_2qhl2  t3_5k52fn  ...                0       0   \n",
       "3  None   1481520805     t5_2qhl2  t3_5huw99  ...                0       0   \n",
       "4  None   1482389580     t5_2qhl2  t3_5jova0  ...                0       0   \n",
       "\n",
       "        id  subreddit   ups distinguished author_flair_css_class  \\\n",
       "0  dbeiwkd       cars  None          None                          \n",
       "1  db7ofxv       cars  None          None                          \n",
       "2  dblvijb       cars  None          None                          \n",
       "3  db372d8       cars  None          None                          \n",
       "4  dbhwl61       cars  None          None                          \n",
       "\n",
       "  normalized_score                                        lemma_array  \\\n",
       "0             33.0  hey|Matt|,|-PRON-|do|not|get|a|chance|to|read|...   \n",
       "1             25.0  what|,|do|-PRON-|fall|down|behind|the|washing|...   \n",
       "2             78.0                  say|the|guy|with|the|rwd|subaru|.   \n",
       "3            100.0  look|about|right|to|-PRON-|[|red|570s](http://...   \n",
       "4             99.0  what|do|-PRON-|think|the|GT|be|go|to|be|worth|...   \n",
       "\n",
       "  body_length  \n",
       "0          26  \n",
       "1          18  \n",
       "2           8  \n",
       "3          21  \n",
       "4          48  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = (\n",
    "    new_df\n",
    "    .assign(\n",
    "        normalized_score = lambda x: x.score.apply(lambda x: norm.cdf(x, loc=6.830742, scale=23.973519)).round(2)*100,\n",
    "        lemma_array = features,\n",
    "    )\n",
    "    .assign(\n",
    "        body_length = lambda x: x.lemma_array.apply(lambda x: len(x.split(\"|\")))\n",
    "    )\n",
    ")\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "colab_type": "code",
    "id": "5YtEEXjfDUe2",
    "outputId": "a4ef0e3e-2396-493f-bee0-99760505593d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>score_hidden</th>\n",
       "      <th>archived</th>\n",
       "      <th>name</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>downs</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>...</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>gilded</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>ups</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>normalized_score</th>\n",
       "      <th>lemma_array</th>\n",
       "      <th>body_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey Matt, I didn't get a chance to read the ar...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>gropingpriest</td>\n",
       "      <td>'09 Cobalt SS t/c</td>\n",
       "      <td>None</td>\n",
       "      <td>1482193840</td>\n",
       "      <td>t5_2qhl2</td>\n",
       "      <td>t3_5j8dou</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dbeiwkd</td>\n",
       "      <td>cars</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>33.0</td>\n",
       "      <td>hey|Matt|,|-PRON-|do|not|get|a|chance|to|read|...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What, did it fall down behind the washing mach...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ArmourChinker</td>\n",
       "      <td>Commodore ����</td>\n",
       "      <td>None</td>\n",
       "      <td>1481770677</td>\n",
       "      <td>t5_2qhl2</td>\n",
       "      <td>t3_5ies4g</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>db7ofxv</td>\n",
       "      <td>cars</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>25.0</td>\n",
       "      <td>what|,|do|-PRON-|fall|down|behind|the|washing|...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Says the guy with the rwd subaru.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2az-fe</td>\n",
       "      <td>13 BMW 535xi, 13 Toyota Highlander, 04 Toyota ...</td>\n",
       "      <td>None</td>\n",
       "      <td>1482648961</td>\n",
       "      <td>t5_2qhl2</td>\n",
       "      <td>t3_5k52fn</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dblvijb</td>\n",
       "      <td>cars</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>78.0</td>\n",
       "      <td>say|the|guy|with|the|rwd|subaru|.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looks about right to me [red 570s](http://www....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>jebusv20</td>\n",
       "      <td>VW Polo GTi 1.4TSI</td>\n",
       "      <td>None</td>\n",
       "      <td>1481520805</td>\n",
       "      <td>t5_2qhl2</td>\n",
       "      <td>t3_5huw99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>db372d8</td>\n",
       "      <td>cars</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>100.0</td>\n",
       "      <td>look|about|right|to|-PRON-|[|red|570s](http://...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What do you think the GT is going to be worth ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Spicy_Curry</td>\n",
       "      <td>2016 340xi ; 2017 GTI</td>\n",
       "      <td>None</td>\n",
       "      <td>1482389580</td>\n",
       "      <td>t5_2qhl2</td>\n",
       "      <td>t3_5jova0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dbhwl61</td>\n",
       "      <td>cars</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>99.0</td>\n",
       "      <td>what|do|-PRON-|think|the|GT|be|go|to|be|worth|...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body score_hidden archived  \\\n",
       "0  Hey Matt, I didn't get a chance to read the ar...         None     None   \n",
       "1  What, did it fall down behind the washing mach...         None     None   \n",
       "2                  Says the guy with the rwd subaru.         None     None   \n",
       "3  looks about right to me [red 570s](http://www....         None     None   \n",
       "4  What do you think the GT is going to be worth ...         None     None   \n",
       "\n",
       "   name         author                                  author_flair_text  \\\n",
       "0  None  gropingpriest                                  '09 Cobalt SS t/c   \n",
       "1  None  ArmourChinker                                     Commodore ����   \n",
       "2  None         2az-fe  13 BMW 535xi, 13 Toyota Highlander, 04 Toyota ...   \n",
       "3  None       jebusv20                                 VW Polo GTi 1.4TSI   \n",
       "4  None    Spicy_Curry                              2016 340xi ; 2017 GTI   \n",
       "\n",
       "  downs  created_utc subreddit_id    link_id  ... controversiality  gilded  \\\n",
       "0  None   1482193840     t5_2qhl2  t3_5j8dou  ...                1       0   \n",
       "1  None   1481770677     t5_2qhl2  t3_5ies4g  ...                0       0   \n",
       "2  None   1482648961     t5_2qhl2  t3_5k52fn  ...                0       0   \n",
       "3  None   1481520805     t5_2qhl2  t3_5huw99  ...                0       0   \n",
       "4  None   1482389580     t5_2qhl2  t3_5jova0  ...                0       0   \n",
       "\n",
       "        id  subreddit   ups distinguished author_flair_css_class  \\\n",
       "0  dbeiwkd       cars  None          None                          \n",
       "1  db7ofxv       cars  None          None                          \n",
       "2  dblvijb       cars  None          None                          \n",
       "3  db372d8       cars  None          None                          \n",
       "4  dbhwl61       cars  None          None                          \n",
       "\n",
       "  normalized_score                                        lemma_array  \\\n",
       "0             33.0  hey|Matt|,|-PRON-|do|not|get|a|chance|to|read|...   \n",
       "1             25.0  what|,|do|-PRON-|fall|down|behind|the|washing|...   \n",
       "2             78.0                  say|the|guy|with|the|rwd|subaru|.   \n",
       "3            100.0  look|about|right|to|-PRON-|[|red|570s](http://...   \n",
       "4             99.0  what|do|-PRON-|think|the|GT|be|go|to|be|worth|...   \n",
       "\n",
       "  body_length  \n",
       "0          26  \n",
       "1          18  \n",
       "2           8  \n",
       "3          21  \n",
       "4          48  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.to_csv(\n",
    "    \"parsed_dataset.tsv\", \n",
    "    sep=\"\\t\", index=False\n",
    ")\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fyHAvTDOk4O5"
   },
   "source": [
    "# Train Word2vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(\"parsed_dataset.tsv\").exists():\n",
    "    data_df = (\n",
    "        pd.read_csv(\"parsed_dataset.tsv\", sep=\"\\t\")\n",
    "        .query(\"body_length > 1 and body_length < 301\")\n",
    "    )\n",
    "    data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "TLyC1QSAMqSx",
    "outputId": "f1129d43-f45f-4834-fcdb-87c66daee1bb"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-01585d9f9ebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             ),\n\u001b[1;32m     12\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         )\n\u001b[1;32m     15\u001b[0m     )\n",
      "\u001b[0;32m~/Documents/anaconda3/envs/graphql_nlp_ml/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbow_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             fast_version=FAST_VERSION)\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     def _do_train_epoch(self, corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch,\n",
      "\u001b[0;32m~/Documents/anaconda3/envs/graphql_nlp_ml/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 end_alpha=self.min_alpha, compute_loss=compute_loss)\n\u001b[0m\u001b[1;32m    764\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrim_rule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/envs/graphql_nlp_ml/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/envs/graphql_nlp_ml/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/envs/graphql_nlp_ml/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[1;32m    552\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[1;32m    554\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
      "\u001b[0;32m~/Documents/anaconda3/envs/graphql_nlp_ml/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[1;32m    487\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[1;32m    488\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             report_delay=report_delay, is_corpus_file_mode=False)\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/envs/graphql_nlp_ml/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/envs/graphql_nlp_ml/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/anaconda3/envs/graphql_nlp_ml/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if Path(\"reddit_vocab.model\").exists():\n",
    "    word_model = Word2Vec.load(\"reddit_vocab.model\")\n",
    "else:\n",
    "    word_model = (\n",
    "        Word2Vec(\n",
    "            list(\n",
    "                map(\n",
    "                    lambda x: x.split('|') if len(x) > 0 else '', \n",
    "                    data_df.lemma_array.tolist()\n",
    "                )\n",
    "            ),\n",
    "            size=100, \n",
    "            iter=1\n",
    "        )\n",
    "    )\n",
    "    word_model.save(\"reddit_vocab.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XrkOr_0RLCqq",
    "outputId": "9808c5ab-bfbf-46b3-986a-8561784fe24c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15135"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_length = len(word_model.wv.vocab)\n",
    "vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "9ZHAirJFSbCL",
    "outputId": "000e3ca0-2e19-4d93-bf96-80363c87c998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    }
   ],
   "source": [
    "vocab_mapper = {\n",
    "    word:pos\n",
    "    for pos, word in enumerate(word_model.wv.vocab, start=2)\n",
    "}\n",
    "print(list(vocab_mapper.keys())[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(vocab_mapper, open(\"storage/transformer/model_vocab.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TjtsUi75UHxx"
   },
   "outputs": [],
   "source": [
    "correct_vocab = [\n",
    "    word_model.wv[word[0]]\n",
    "    for word in sorted(vocab_mapper.items(), key=lambda x: x[1])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "91OH2P1mIbqW"
   },
   "outputs": [],
   "source": [
    "fill_vectors = [\n",
    "  np.zeros(100),\n",
    "  np.random.uniform(\n",
    "      np.stack(correct_vocab).min(),\n",
    "      np.stack(correct_vocab).max(),\n",
    "      size=100,\n",
    "  )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "hX2XIK1FJPGO",
    "outputId": "e73c41b7-25f8-49d7-c51c-d5707d613da4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15137, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 2.75489497e+00, -4.05982283e+00, -3.01992025e-01, ...,\n",
       "         5.26690822e+00, -6.07171475e+00,  5.69176936e+00],\n",
       "       [-1.00234616e+00, -5.83511412e-01,  4.95817602e-01, ...,\n",
       "         7.56369710e-01,  8.26566219e-01,  1.92568326e+00],\n",
       "       ...,\n",
       "       [ 1.65504724e-01,  3.61217968e-02,  2.61429191e-01, ...,\n",
       "        -3.69425416e-01,  5.30689619e-02, -2.24623859e-01],\n",
       "       [-3.18039656e-02,  1.26783118e-01, -1.26064330e-01, ...,\n",
       "        -2.41369940e-03,  4.62743193e-01, -6.72298297e-02],\n",
       "       [ 4.77407664e-01, -1.92143098e-01,  2.03233689e-01, ...,\n",
       "         5.50392494e-02,  5.57754159e-01, -6.53721020e-02]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_vocab = np.stack(fill_vectors + correct_vocab)\n",
    "print(correct_vocab.shape)\n",
    "correct_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5BBeJMNOlq83"
   },
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.0     40815\n",
       "42.0     18365\n",
       "44.0     10046\n",
       "45.0      4331\n",
       "47.0      4154\n",
       "49.0      3133\n",
       "39.0      2768\n",
       "50.0      2463\n",
       "52.0      1855\n",
       "54.0      1495\n",
       "100.0     1342\n",
       "55.0      1306\n",
       "57.0      1085\n",
       "37.0       940\n",
       "59.0       887\n",
       "60.0       762\n",
       "62.0       701\n",
       "63.0       557\n",
       "65.0       533\n",
       "Name: normalized_score, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_groups = data_df.normalized_score.value_counts()\n",
    "score_groups[score_groups > 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GAwOBHA5Fo9g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1900, 23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57.0     100\n",
       "50.0     100\n",
       "39.0     100\n",
       "40.0     100\n",
       "42.0     100\n",
       "44.0     100\n",
       "45.0     100\n",
       "47.0     100\n",
       "49.0     100\n",
       "52.0     100\n",
       "65.0     100\n",
       "54.0     100\n",
       "59.0     100\n",
       "60.0     100\n",
       "62.0     100\n",
       "63.0     100\n",
       "100.0    100\n",
       "55.0     100\n",
       "37.0     100\n",
       "Name: normalized_score, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set = (\n",
    "    data_df\n",
    "    .query(f\"normalized_score in {score_groups[score_groups > 500].index.tolist()}\")\n",
    "    .groupby(\"normalized_score\")\n",
    "    .apply(lambda x: x.sample(min(len(x)-2, 100), random_state=100))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(validation_set.shape)\n",
    "validation_set.normalized_score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57.0     100\n",
       "50.0     100\n",
       "39.0     100\n",
       "40.0     100\n",
       "42.0     100\n",
       "44.0     100\n",
       "45.0     100\n",
       "47.0     100\n",
       "49.0     100\n",
       "52.0     100\n",
       "54.0     100\n",
       "59.0     100\n",
       "60.0     100\n",
       "55.0     100\n",
       "37.0     100\n",
       "62.0      98\n",
       "63.0      85\n",
       "65.0      67\n",
       "100.0     47\n",
       "Name: normalized_score, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = (\n",
    "    data_df\n",
    "    .query(f\"link_id not in {validation_set.link_id.tolist()}\")\n",
    "    .query(f\"normalized_score in {score_groups[score_groups > 500].index.tolist()}\")\n",
    "    .groupby(\"normalized_score\")\n",
    "    .apply(lambda x: x.sample(min(len(x), 100), random_state=100))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(test_set.shape)\n",
    "test_set.normalized_score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12444, 23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40.0    7640\n",
       "42.0    2312\n",
       "44.0    1003\n",
       "45.0     315\n",
       "47.0     280\n",
       "39.0     243\n",
       "49.0     200\n",
       "50.0     116\n",
       "52.0      67\n",
       "54.0      38\n",
       "55.0      28\n",
       "36.0      27\n",
       "37.0      22\n",
       "57.0      18\n",
       "59.0      16\n",
       "66.0      14\n",
       "33.0      13\n",
       "34.0      12\n",
       "68.0      10\n",
       "71.0       8\n",
       "69.0       8\n",
       "30.0       7\n",
       "74.0       6\n",
       "31.0       6\n",
       "72.0       5\n",
       "28.0       5\n",
       "75.0       4\n",
       "81.0       2\n",
       "78.0       2\n",
       "79.0       2\n",
       "96.0       2\n",
       "25.0       2\n",
       "76.0       2\n",
       "89.0       2\n",
       "60.0       1\n",
       "87.0       1\n",
       "94.0       1\n",
       "24.0       1\n",
       "6.0        1\n",
       "80.0       1\n",
       "88.0       1\n",
       "Name: normalized_score, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = (\n",
    "    data_df\n",
    "    .query(f\"link_id not in {validation_set.link_id.tolist()}\")\n",
    "    .query(f\"link_id not in {test_set.link_id.tolist()}\")\n",
    ")\n",
    "print(training_set.shape)\n",
    "training_set.normalized_score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = {\n",
    "    \"train\":training_set,\n",
    "    \"validation\": validation_set,\n",
    "    \"test\":test_set\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZTkEnvMijThL",
    "outputId": "7092363a-61fc-41c4-d6c1-a41ac5badc0e"
   },
   "outputs": [],
   "source": [
    "Y_map = {\n",
    "    label:torch.FloatTensor(df_map[label].normalized_score.tolist())\n",
    "    for label in df_map\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Bsf19cCjV0aR",
    "outputId": "6ad1ddbb-1a85-4bde-cf14-ae2c9714cf66"
   },
   "outputs": [],
   "source": [
    "X_map = {\n",
    "    label:[\n",
    "      list(\n",
    "          map(\n",
    "              lambda tok: vocab_mapper[tok] if tok in vocab_mapper else 1, \n",
    "              comment_lemma.split(\"|\")\n",
    "          )\n",
    "      ) \n",
    "      for comment_lemma in df_map[label].lemma_array.tolist()\n",
    "    ]\n",
    "    for label in df_map\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "igmU1FnXXZER",
    "outputId": "a1666fc0-cf3c-4486-eebe-d695f57494bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "max_length = max([\n",
    "    max(list(map(lambda x: len(x), X_map[dataset])))\n",
    "    for dataset in X_map\n",
    "])\n",
    "print(max_length)\n",
    "max_length = max(max_length, 300)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "juIyGMNeZaij",
    "outputId": "53ffe9b6-a691-4f1c-b64f-cfa7b6a7abe7"
   },
   "outputs": [],
   "source": [
    "X_map = {\n",
    "    label:torch.stack([\n",
    "        torch.LongTensor(np.pad(data, (0,max_length-len(data)), 'constant', constant_values=0))\n",
    "        for data in X_map[label]\n",
    "    ])\n",
    "    for label in X_map\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13x6KSienlub"
   },
   "outputs": [],
   "source": [
    "data_loader_map = {\n",
    "    label:data.DataLoader(\n",
    "        data.TensorDataset(X_map[label], Y_map[label]), \n",
    "        batch_size=128,\n",
    "        shuffle= (label=='train')\n",
    "    )\n",
    "    for label in X_map\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_grid = [0.1, 1e-3, 1e-5]\n",
    "epochs_grid = [50]\n",
    "dropout_grid = [\n",
    "    [0.25, 0.25, 0.25, 0.25, 0.25],\n",
    "    [0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "    [0.75, 0.75, 0.75, 0.75, 0.75]\n",
    "]\n",
    "#loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final best Parameters\n",
    "dropout_grid = [[0.25, 0.25, 0.25, 0.25, 0.25]]\n",
    "learning_rate_grid = [1e-3]\n",
    "epochs_grid = [100]#, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Huh7mlfbmrUi",
    "outputId": "036be532-28f0-4f03-981b-28e961877951"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [49:41<00:00, 29.52s/it]\n"
     ]
    }
   ],
   "source": [
    "from ml_model import RedditTransformerPredictor\n",
    "training_grid = itertools.product(epochs_grid, learning_rate_grid, dropout_grid)\n",
    "for epoch_param, lr_param, dropout_param in training_grid:\n",
    "\n",
    "    predictor_model = RedditTransformerPredictor(\n",
    "        torch.FloatTensor(correct_vocab), \n",
    "        max_length=max_length,\n",
    "        vocab_dim=100,\n",
    "        dropout=dropout_param\n",
    "    )\n",
    "    \n",
    "    writer = SummaryWriter(\n",
    "        \"storage/param_sweep/transformer/\"\n",
    "        f\"{epoch_param, str(lr_param), ','.join(map(str,dropout_param)), 2}\"\n",
    "    )\n",
    "    optimizer = opt.Adam(predictor_model.parameters(), lr=lr_param)\n",
    "    \n",
    "    for epoch in tqdm.tqdm(range(epoch_param+1)):\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            predictor_model.cuda()\n",
    "        \n",
    "        # Check to make sure the network starts off as random\n",
    "        if epoch > 0:\n",
    "            epoch_loss = []\n",
    "            \n",
    "            for batch in data_loader_map['train']:\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    batch[0] = batch[0].cuda()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                prediction = predictor_model(batch[0]).cpu()\n",
    "                loss = loss_fn(prediction, batch[1].unsqueeze(dim=1))\n",
    "                epoch_loss.append(loss.item())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            writer.add_scalar(\"Loss/train\", np.mean(epoch_loss), epoch)\n",
    "\n",
    "        # Set model to evaluation\n",
    "        predictor_model.eval()\n",
    "        \n",
    "        val_loss = []\n",
    "        for batch in data_loader_map['validation']:\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                batch[0] = batch[0].cuda()\n",
    "            \n",
    "            prediction = predictor_model(batch[0])\n",
    "            loss = loss_fn(prediction.cpu(), batch[1].unsqueeze(dim=1))\n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "        \n",
    "        writer.add_scalar(\"Loss/val\", np.mean(val_loss), epoch)\n",
    "\n",
    "        # Set model for training\n",
    "        predictor_model.train()\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:01<00:00, 10.48it/s]\n"
     ]
    }
   ],
   "source": [
    "predictor_model.eval()\n",
    "test_loss = []\n",
    "for batch in tqdm.tqdm(data_loader_map['test']):\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        batch[0] = batch[0].cuda()\n",
    "\n",
    "    prediction = predictor_model(batch[0])\n",
    "    loss = loss_fn(prediction.cpu(), batch[1].unsqueeze(dim=1))\n",
    "    test_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565.4683766682942\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    predictor_model.state_dict(), \n",
    "   \"storage/transformer/reddit_transformer_predictor.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RedditTransformerPredictor(\n",
       "  (input_layer): Embedding(15137, 100)\n",
       "  (encoder_layer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): _LinearWithBias(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear2): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=100, out_features=100, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=100, out_features=50, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=50, out_features=100, bias=True)\n",
       "        (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=100, out_features=100, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=100, out_features=50, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=50, out_features=100, bias=True)\n",
       "        (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=100, out_features=100, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=100, out_features=50, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=50, out_features=100, bias=True)\n",
       "        (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): _LinearWithBias(in_features=100, out_features=100, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=100, out_features=50, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=50, out_features=100, bias=True)\n",
       "        (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer1): Linear(in_features=30000, out_features=500, bias=True)\n",
       "  (layer2): Linear(in_features=500, out_features=300, bias=True)\n",
       "  (layer3): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (layer4): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (layer5): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (layer6): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list(predictor_model.named_parameters())\n",
    "predictor_model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bigquery_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
